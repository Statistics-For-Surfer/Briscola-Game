---
title: "Statistical Learning Project"
author: "1st Milestone"
date: "Group 5: Paolo Barba, Matteo Candi, Silvia Costantini, Maria Vittoria Vestini."
output: pdf_document
urlcolor: magenta
linkcolor: cyan
geometry: margin=1.25cm
fontsize: 12pt
header-includes:
- \usepackage{bbold}
- \usepackage{mdframed, xcolor}
- \usepackage{graphicx}
- \mdfsetup{frametitlealignment=\center}
- \usepackage{multirow}
- \definecolor{shadecolor}{rgb}{0.89,0.8,1}
- \newcommand{\Prob}{\mathbb{P}}
- \newcommand{\Exp}{\mathbb{E}}
- \newcommand{\Var}{\mathbb{V}\mathrm{ar}}
- \newcommand{\Cov}{\mathbb{C}\mathrm{ov}}
- \newcommand{\blue}{\textcolor{blue}}
- \newcommand{\darkgreen}{\textcolor[rgb]{0,.5,0}}
- \newcommand{\gray}{\textcolor[rgb]{.3,.3,.3}}
- \newcommand{\blueA}{\textcolor[rgb]{0,.1,.4}}
- \newcommand{\blueB}{\textcolor[rgb]{0,.3,.6}}
- \newcommand{\blueC}{\textcolor[rgb]{0,.5,.8}}
- \newcommand{\evidenzia}{\textcolor[rgb]{0,0,0}}
- \newcommand{\nero}{\textcolor[rgb]{0,0,0}}
- \newcommand{\darkyel}{\textcolor[rgb]{.4,.4,0}}
- \newcommand{\darkred}{\textcolor[rgb]{.6,0,0}}
- \newcommand{\blueDek}{\textcolor[rgb]{0.6000000, 0.7490196, 0.9019608}}
- \newcommand{\purpLarry}{\textcolor[rgb]{0.6901961, 0.2431373, 0.4784314}}
- \newcommand{\lightgray}{\textcolor[rgb]{.8,.8,.8}}
- \newcommand{\bfun}{\left\{\begin{array}{ll}}
- \newcommand{\efun}{\end{array}\right.}
editor_options: 
  markdown: 
    wrap: sentence
---

## Research Title

"Pausetta Briscola?"

------------------------------------------------------------------------

## Abstract

Apply reinforcement algorithm in order to teach an agent how to play Briscola.

------------------------------------------------------------------------

## Main research aim & framework

The main goal of our project is to implement an agent capable to play the Italian popular game "Briscola" better than a random agent.

The reason way we choose this as our project is that we have been playing this game since we were kids, and we think it could be interesting to teach an agent how to play it properly and then challenge it.
We will see if our 12 years of training will be enough to beat an agent that has trained for definitely less time.

The secondary goal is to create a "Briscola Engine" with different levels of skills to use as an app in order to give the users the possibility to improve in this card game.

Relevant material:

-   $\href{https://www.youtube.com/watch?v=0AItpwiVFnU&t=95s}{Hearts\ Reinforcement\ Learning\ with\ MDP\ model}$

-   $\href{https://web.stanford.edu/class/aa228/reports/2020/final117.pdf}{Beating \ Blackjack - A \ Reinforcement \ Learning \ Approach}$

-   $\href{https://github.com/alisatodorova/Briscola-Project/blob/main/FinalReport.pdf}{Applications \ of \ Adversarial \ Search \ and \ Machine \ Learning \ in \ Briscola}$

------------------------------------------------------------------------

## IML paper(s) you like (at this point!)

$\href{https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf}{Reinforcement \ Learning: \ An \ Introduction}$

------------------------------------------------------------------------

## Data

For this type of project we will not need to collect/search for external data, but it will all be generated via game's simulations.

------------------------------------------------------------------------

## Model & Methods

Based on the material we found, we think that the main models and method we could use are:

-   MDP-model (Markov Decision Process).

-   Deep Q-Learning.

-   Monte Carlo Tree Search.

------------------------------------------------------------------------

## Software/Hardware Toolkit

Programming languages: R , Python.

Since we have yet to start the project, we are not sure about which will be the needed packages, modules or frameworks.

We will try with our computers but can be possible that they will be not enough to handle the process.

------------------------------------------------------------------------

## References

-   R. Sutton and A.
    Barto (2014), *Reinforcement Learning: An Introduction*.

-   J. Geiser, T. Hasseler(2020), *Beating Blackjack - A Reinforcement Learning Approach*.

-   H. Konduru, O. Von Moeller, P. Mohri, J. Monedero Simon, A. Safi, A. Todorova, *Applications of Adversarial Search and Machine Learning in Briscola*.

------------------------------------------------------------------------
